{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2aa4441-aa0e-47d4-9435-575f6a11195f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run VECTOR_DB_BUILD.ipynb     #this is were my function was stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95db3601-9f21-45c7-89a0-ca829992507c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer\n",
    "import accelerate\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86e60404-aaa1-4311-89e5-44c2b6ad0dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87dce72162ad4ffbb1f3e750563b5a13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "READER_MODEL_NAME = \"HuggingFaceH4/zephyr-7b-beta\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    READER_MODEL_NAME, quantization_config=bnb_config\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(READER_MODEL_NAME)\n",
    "\n",
    "READER_LLM = pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    do_sample=True,\n",
    "    temperature=0.2,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=False,\n",
    "    max_new_tokens=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23d7809c-209d-468e-bd21-621cf99dae18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "Using the information contained in the context,\n",
      "give a comprehensive answer to the question.\n",
      "Respond only to the question asked, response should be concise and relevant to the question.\n",
      "Provide the number of the source document when relevant.\n",
      "If the answer cannot be deduced from the context, do not give an answer.</s>\n",
      "<|user|>\n",
      "Context:\n",
      "{context}\n",
      "---\n",
      "Now here is the question you need to answer.\n",
      "\n",
      "Question: {question}</s>\n",
      "<|assistant|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_in_chat_format = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"Using the information contained in the context,\n",
    "give a comprehensive answer to the question.\n",
    "Respond only to the question asked, response should be concise and relevant to the question.\n",
    "Provide the number of the source document when relevant.\n",
    "If the answer cannot be deduced from the context, do not give an answer.\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"Context:\n",
    "{context}\n",
    "---\n",
    "Now here is the question you need to answer.\n",
    "\n",
    "Question: {question}\"\"\",\n",
    "    },\n",
    "]\n",
    "RAG_PROMPT_TEMPLATE = tokenizer.apply_chat_template(\n",
    "    prompt_in_chat_format, tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "print(RAG_PROMPT_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f460fb6-931a-4a3c-8b90-f4a82660f090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask your question\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " What is an LLM?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask your question\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " What is the difference between a sql data base and a vector data base?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask your question\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " how to book a movie ticket?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask your question\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " what is BSP domain controllers?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask your question\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " what are the MSP high level requirements?\n"
     ]
    }
   ],
   "source": [
    "questions = []\n",
    "for i in range(5):\n",
    "    print('Ask your question')\n",
    "    q = str(input())\n",
    "    questions.append(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed92c161-e898-4a64-b4c6-b92038229602",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c470a3fb23194a5286c434d69fcee204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An LLM (Large Language Model) is a type of artificial intelligence algorithm that can generate human-like text based on a given prompt or input. It uses deep learning techniques to process large amounts of text data and can perform tasks such as language translation, summarization, and question answering with high accuracy. In some cases, LLMs are also used for text generation and creative writing purposes. (Source: Document 0)\n",
      "\n",
      "In more detail, LLMs are trained on vast datasets of text, typically billions of words, using unsupervised learning methods. They learn to predict the next word in a sequence based on the context of the previous words, allowing them to generate coherent and meaningful text. Some popular examples of LLMs include GPT-3 (Generative Pretrained Transformer 3), BERT (Bidirectional Encoder Representations from Transformers), and RoBERT (Robustly Optimized BERT Pretraining Approach). (Sources: Documents 1-3)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98932e2cd71d4137807246725113b616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A SQL (Structured Query Language) database stores and manages structured data in tables with defined schemas. It allows for querying, updating, and deleting data using SQL statements. In contrast, a vector database, such as those offered by LlamaIndex, stores pre-computed vector representations of text data for fast retrieval and similarity search. Instead of searching through text, it performs calculations on numerical vectors that represent the meaning or semantic content of the text. This allows for more efficient and accurate search results based on similarity rather than exact matches. While SQL databases are useful for storing and managing structured data, vector databases excel at handling large volumes of unstructured text data for tasks like information retrieval and recommendation systems. (Answer provided based on the given context.)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6abd1ea6c79490a8b9a718916f0650c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, it does not offer information on how to book a movie ticket. The extracts only provide URLs that allow third-party ticketing providers to access specific subscriber records. To answer your question, you may need to provide additional context or details about the location and theater where you wish to watch the movie. Without this information, it is impossible to provide a comprehensive answer.\n",
      "\n",
      "However, if you have identified a specific theater or chain that offers online booking, you can visit their website or mobile app and follow the steps to select the desired movie, date, time, and seats. Alternatively, you can use popular ticketing platforms like Bookmyshow (https://in.bookmyshow.com/), Paytm (https://movie.paytm.com/), or Insider (https://insider.in/) to find and book tickets for various theaters across India. These websites and apps offer a simple and convenient way to reserve your seat and receive e-tickets via email or SMS.\n",
      "\n",
      "In summary, to book a movie ticket, you need to identify the theater and showtime, visit the preferred ticketing platform, select the desired seats, and complete the payment process. If you require further assistance, please let me know, and I will try my best to help you.\n",
      "\n",
      "Note: This answer assumes that the context provided is accurate and relevant to your query. If you believe there is any discrepancy or error, please inform me, and I will update my response accordingly.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b20fbe3b0a224c82b2aadd3b5f8ac26d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the provided context, BSP domain controllers refer to the network infrastructure managed by the BSP (Broadband Service Provider) that hosts the high-level requirements for Tier 1 in Calix Cloud. This means that Calix Cloud runs within this network infrastructure managed by the BSP. The exact functionality and responsibilities of these domain controllers are not explicitly defined in the given context, but they appear to play a role in managing the network environment for Calix Cloud at the Tier 1 level. Document 1, 2, and 3 each provide a summary of the high-level requirements for BSP domain controllers at Tier 1, suggesting that there may be some variation or customization required depending on the specific deployment scenario. However, it's unclear whether all Tier 2 deployments require BSP domain controllers or if they can opt to use only the Access Controller component instead. Further details about the BSP domain controllers would likely be found in the full documentation or implementation guides for Calix Cloud.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d759035e7be14279883c3ea67d97021c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on Documents 1-3 provided, the MSP (managed service provider) high level requirements can be summarized as follows:\n",
      "\n",
      "1. Scale and hardware guidelines are similar to those for standalone instances (SMx).\n",
      "2. Detailed requirements may vary depending on specific MSP scenarios, but high-level goals include providing examples, rephrasing queries, and stating the overall objective at a broad level.\n",
      "\n",
      "Unfortunately, without access to the full content of these documents, it's impossible to provide more detailed or specific requirements beyond what has been stated. However, based on this information, it's clear that the MSP requirements share some similarities with those for standalone instances, while also having unique needs related to managing services for multiple clients.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for questions in questions:\n",
    "    retrieved_docs = main_retriever.get_relevant_documents(questions)\n",
    "    retrieved_docs_text = [\n",
    "        doc.page_content for doc in retrieved_docs\n",
    "    ]  # we only need the text of the documents\n",
    "    context = \"\\nExtracted documents:\\n\"\n",
    "    context += \"\".join(\n",
    "        [f\"Document {str(i)}:::\\n\" + doc for i, doc in enumerate(retrieved_docs_text)]\n",
    "    )\n",
    "    final_prompt = RAG_PROMPT_TEMPLATE.format(\n",
    "        question=questions, context=context\n",
    "    )\n",
    "        \n",
    "    # Redact an answer\n",
    "    answer = READER_LLM(final_prompt)[0][\"generated_text\"]\n",
    "    print(answer)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3f0588-8f55-41ae-98ae-3c0a5fd75f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64a16c9-3ee5-4137-a6fa-5703e8ebf88a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930bd3b1-c116-4194-8437-800af4702af7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
